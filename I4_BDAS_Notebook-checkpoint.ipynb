{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Iteration 4: BDAS - PySpark + Colab + AWS\n",
        "## Life Expectancy Prediction with Spark MLlib\n",
        "\n",
        "This notebook implements the complete data science pipeline using PySpark for big data analytics based on the I3.py analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Environment Setup and Spark Installation\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages for Spark environment\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "\n",
        "# Download and setup Spark 3.5.0\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.0-bin-hadoop3.tgz\n",
        "\n",
        "# Install Python packages\n",
        "!pip install findspark pyspark==3.5.0\n",
        "\n",
        "import os\n",
        "import findspark\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.0-bin-hadoop3\"\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import *\n",
        "from pyspark.ml.regression import *\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Initialize SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"LifeExpectancyPrediction\") \\\n",
        "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
        "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "print(f\"Spark version: {spark.version}\")\n",
        "spark\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 导入并检查数据\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 从 CSV 加载 WHO Life Expectancy 数据集\n",
        "df = spark.read.options(header=True, inferSchema=True).csv(\"Life Expectancy Data.csv\")\n",
        "\n",
        "# 自动推断字段类型、打印 schema 与前 5 行样例\n",
        "print(\"Data Schema:\")\n",
        "df.printSchema()\n",
        "\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "df.show(5)\n",
        "\n",
        "# 统计总行数与各列缺失数量\n",
        "total_rows = df.count()\n",
        "print(f\"\\nTotal rows: {total_rows}\")\n",
        "\n",
        "print(\"\\nMissing values per column:\")\n",
        "missing_stats = df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns])\n",
        "missing_stats.show(1, vertical=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 清洗数据\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 转换数据类型和处理缺失值\n",
        "numeric_columns = ['Life expectancy ', 'Adult Mortality', 'infant deaths', 'Alcohol', \n",
        "                   'percentage expenditure', 'Hepatitis B', 'Measles ', ' BMI ', \n",
        "                   'under-five deaths ', 'Polio', 'Total expenditure', 'Diphtheria ', \n",
        "                   ' HIV/AIDS', 'GDP', 'Population', ' thinness  1-19 years', \n",
        "                   ' thinness 5-9 years', 'Income composition of resources', 'Schooling']\n",
        "\n",
        "# 转换为适当的数据类型\n",
        "df_clean = df\n",
        "for col_name in numeric_columns:\n",
        "    if col_name in df.columns:\n",
        "        df_clean = df_clean.withColumn(col_name, col(col_name).cast(\"double\"))\n",
        "\n",
        "# 确保 Year 是整数\n",
        "df_clean = df_clean.withColumn(\"Year\", col(\"Year\").cast(\"int\"))\n",
        "\n",
        "# 用均值填补数值缺失\n",
        "numeric_means = {}\n",
        "for col_name in numeric_columns:\n",
        "    if col_name in df_clean.columns:\n",
        "        mean_val = df_clean.select(mean(col(col_name))).collect()[0][0]\n",
        "        numeric_means[col_name] = mean_val if mean_val is not None else 0.0\n",
        "\n",
        "for col_name, mean_val in numeric_means.items():\n",
        "    df_clean = df_clean.withColumn(col_name, when(col(col_name).isNull(), mean_val).otherwise(col(col_name)))\n",
        "\n",
        "# 用 \"Developing\" 填补 Status\n",
        "df_clean = df_clean.withColumn(\"Status\", when(col(\"Status\").isNull(), \"Developing\").otherwise(col(\"Status\")))\n",
        "\n",
        "# 校正不合理值（如疫苗覆盖率 > 100 或 < 0）\n",
        "vaccine_cols = ['Hepatitis B', 'Polio', 'Diphtheria ']\n",
        "for vaccine_col in vaccine_cols:\n",
        "    if vaccine_col in df_clean.columns:\n",
        "        df_clean = df_clean.withColumn(vaccine_col, \n",
        "            when(col(vaccine_col) > 100, 100.0)\n",
        "            .when(col(vaccine_col) < 0, 0.0)\n",
        "            .otherwise(col(vaccine_col)))\n",
        "\n",
        "print(\"Data cleaning completed.\")\n",
        "print(\"\\nSummary statistics:\")\n",
        "df_clean.describe().show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 构造新特征\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import log, log1p\n",
        "\n",
        "# 基于 I3.py 特征工程部分创建新特征\n",
        "df_features = df_clean\n",
        "\n",
        "# 1. log_GDP：GDP 取对数\n",
        "df_features = df_features.withColumn(\"log_GDP\", log1p(col(\"GDP\") + 1e-6))\n",
        "\n",
        "# 2. immunization_avg：三种疫苗平均\n",
        "vaccine_cols = ['Hepatitis B', 'Polio', 'Diphtheria ']\n",
        "available_vaccine_cols = [c for c in vaccine_cols if c in df_features.columns]\n",
        "if available_vaccine_cols:\n",
        "    df_features = df_features.withColumn(\"immunization_avg\", \n",
        "        sum(*[col(vc) for vc in available_vaccine_cols]) / len(available_vaccine_cols))\n",
        "\n",
        "# 3. mortality_ratio：婴儿死亡率比\n",
        "if 'infant deaths' in df_features.columns and 'under-five deaths ' in df_features.columns and 'Adult Mortality' in df_features.columns:\n",
        "    df_features = df_features.withColumn(\"child_mortality_rate\", \n",
        "        col('infant deaths') + col('under-five deaths '))\n",
        "    df_features = df_features.withColumn(\"mortality_ratio\", \n",
        "        col('child_mortality_rate') / (col('Adult Mortality') + 1e-6))\n",
        "\n",
        "# 4. health_spend_pc：人均健康支出\n",
        "if 'percentage expenditure' in df_features.columns and 'Population' in df_features.columns:\n",
        "    df_features = df_features.withColumn(\"health_spend_pc\", \n",
        "        col('percentage expenditure') / (col('Population') + 1e-6))\n",
        "\n",
        "# 基于 I3.py 的额外特征\n",
        "if 'percentage expenditure' in df_features.columns and 'GDP' in df_features.columns:\n",
        "    df_features = df_features.withColumn('health_expenditure_ratio', \n",
        "        col('percentage expenditure') / (col('GDP') + 1e-6))\n",
        "\n",
        "disease_cols = ['Measles ', 'Polio', 'Diphtheria ']\n",
        "if 'GDP' in df_features.columns and 'Income composition of resources' in df_features.columns:\n",
        "    df_features = df_features.withColumn('economic_dev_index', \n",
        "        col('GDP') * col('Income composition of resources'))\n",
        "\n",
        "print(\"New features created.\")\n",
        "new_feature_cols = [c for c in df_features.columns if c not in df_clean.columns]\n",
        "print(f\"New features: {new_feature_cols}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 整合与丰富数据\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 为 Country 增加 Region 字段\n",
        "region_data = {\n",
        "    'Afghanistan': 'South Asia', 'Albania': 'Europe', 'Algeria': 'North Africa', \n",
        "    'Argentina': 'South America', 'Armenia': 'Europe', 'Australia': 'Oceania',\n",
        "    'Austria': 'Europe', 'Azerbaijan': 'Europe', 'Bahamas': 'Caribbean',\n",
        "    'Bahrain': 'Middle East', 'Bangladesh': 'South Asia', 'Barbados': 'Caribbean',\n",
        "    'Belarus': 'Europe', 'Belgium': 'Europe', 'Belize': 'Central America',\n",
        "    'Benin': 'West Africa', 'Bhutan': 'South Asia', 'Bolivia': 'South America',\n",
        "    'Bosnia and Herzegovina': 'Europe', 'Botswana': 'Southern Africa', 'Brazil': 'South America',\n",
        "    'Brunei': 'Southeast Asia', 'Bulgaria': 'Europe', 'Burkina Faso': 'West Africa',\n",
        "    'Burundi': 'East Africa', 'Cabo Verde': 'West Africa', 'Cambodia': 'Southeast Asia',\n",
        "    'Cameroon': 'Central Africa', 'Canada': 'North America', 'Central African Republic': 'Central Africa',\n",
        "    'Chad': 'Central Africa', 'Chile': 'South America', 'China': 'East Asia',\n",
        "    'Colombia': 'South America', 'Comoros': 'East Africa', 'Congo': 'Central Africa',\n",
        "    'Costa Rica': 'Central America', \"Cote d'Ivoire\": 'West Africa', 'Croatia': 'Europe',\n",
        "    'Cuba': 'Caribbean', 'Cyprus': 'Europe', 'Czech Republic': 'Europe',\n",
        "    'Denmark': 'Europe', 'Djibouti': 'East Africa', 'Dominican Republic': 'Caribbean',\n",
        "    'Ecuador': 'South America', 'Egypt': 'North Africa', 'El Salvador': 'Central America',\n",
        "    'Eritrea': 'East Africa', 'Estonia': 'Europe', 'Ethiopia': 'East Africa',\n",
        "    'Fiji': 'Oceania', 'Finland': 'Europe', 'France': 'Europe',\n",
        "    'Gabon': 'Central Africa', 'Gambia': 'West Africa', 'Georgia': 'Europe',\n",
        "    'Germany': 'Europe', 'Ghana': 'West Africa', 'Greece': 'Europe',\n",
        "    'Grenada': 'Caribbean', 'Guatemala': 'Central America', 'Guinea': 'West Africa',\n",
        "    'Guinea-Bissau': 'West Africa', 'Guyana': 'South America', 'Haiti': 'Caribbean',\n",
        "    'Honduras': 'Central America', 'Hungary': 'Europe', 'Iceland': 'Europe',\n",
        "    'India': 'South Asia', 'Indonesia': 'Southeast Asia', 'Iran': 'Middle East',\n",
        "    'Iraq': 'Middle East', 'Ireland': 'Europe', 'Israel': 'Middle East',\n",
        "    'Italy': 'Europe', 'Jamaica': 'Caribbean', 'Japan': 'East Asia',\n",
        "    'Jordan': 'Middle East', 'Kazakhstan': 'Central Asia', 'Kenya': 'East Africa',\n",
        "    'Kiribati': 'Oceania', 'Kuwait': 'Middle East', 'Kyrgyzstan': 'Central Asia',\n",
        "    'Laos': 'Southeast Asia', 'Latvia': 'Europe', 'Lebanon': 'Middle East',\n",
        "    'Lesotho': 'Southern Africa', 'Liberia': 'West Africa', 'Libya': 'North Africa',\n",
        "    'Lithuania': 'Europe', 'Luxembourg': 'Europe', 'Madagascar': 'East Africa',\n",
        "    'Malawi': 'East Africa', 'Malaysia': 'Southeast Asia', 'Maldives': 'South Asia',\n",
        "    'Mali': 'West Africa', 'Malta': 'Europe', 'Mauritania': 'North Africa',\n",
        "    'Mauritius': 'East Africa', 'Mexico': 'North America', 'Mongolia': 'East Asia',\n",
        "    'Montenegro': 'Europe', 'Morocco': 'North Africa', 'Mozambique': 'East Africa',\n",
        "    'Myanmar': 'Southeast Asia', 'Namibia': 'Southern Africa', 'Nepal': 'South Asia',\n",
        "    'Netherlands': 'Europe', 'New Zealand': 'Oceania', 'Nicaragua': 'Central America',\n",
        "    'Niger': 'West Africa', 'Nigeria': 'West Africa', 'Norway': 'Europe',\n",
        "    'Oman': 'Middle East', 'Pakistan': 'South Asia', 'Panama': 'Central America',\n",
        "    'Papua New Guinea': 'Oceania', 'Paraguay': 'South America', 'Peru': 'South America',\n",
        "    'Philippines': 'Southeast Asia', 'Poland': 'Europe', 'Portugal': 'Europe',\n",
        "    'Qatar': 'Middle East', 'Romania': 'Europe', 'Russia': 'Europe',\n",
        "    'Rwanda': 'East Africa', 'Samoa': 'Oceania', 'Saudi Arabia': 'Middle East',\n",
        "    'Senegal': 'West Africa', 'Serbia': 'Europe', 'Seychelles': 'East Africa',\n",
        "    'Sierra Leone': 'West Africa', 'Singapore': 'Southeast Asia', 'Slovakia': 'Europe',\n",
        "    'Slovenia': 'Europe', 'Solomon Islands': 'Oceania', 'Somalia': 'East Africa',\n",
        "    'South Africa': 'Southern Africa', 'South Korea': 'East Asia', 'South Sudan': 'East Africa',\n",
        "    'Spain': 'Europe', 'Sri Lanka': 'South Asia', 'Sudan': 'North Africa',\n",
        "    'Suriname': 'South America', 'Swaziland': 'Southern Africa', 'Sweden': 'Europe',\n",
        "    'Switzerland': 'Europe', 'Syria': 'Middle East', 'Tajikistan': 'Central Asia',\n",
        "    'Tanzania': 'East Africa', 'Thailand': 'Southeast Asia', 'Timor-Leste': 'Southeast Asia',\n",
        "    'Togo': 'West Africa', 'Tonga': 'Oceania', 'Trinidad and Tobago': 'Caribbean',\n",
        "    'Tunisia': 'North Africa', 'Turkey': 'Europe', 'Turkmenistan': 'Central Asia',\n",
        "    'Uganda': 'East Africa', 'Ukraine': 'Europe', 'United Arab Emirates': 'Middle East',\n",
        "    'United Kingdom': 'Europe', 'United States of America': 'North America', 'Uruguay': 'South America',\n",
        "    'Uzbekistan': 'Central Asia', 'Vanuatu': 'Oceania', 'Venezuela': 'South America',\n",
        "    'Vietnam': 'Southeast Asia', 'Yemen': 'Middle East', 'Zambia': 'East Africa', 'Zimbabwe': 'East Africa'\n",
        "}\n",
        "\n",
        "region_df = spark.createDataFrame(\n",
        "    [(country, region) for country, region in region_data.items()],\n",
        "    [\"Country\", \"Region\"]\n",
        ")\n",
        "\n",
        "df_enriched = df_features.join(region_df, \"Country\", \"left\")\n",
        "df_enriched = df_enriched.withColumn(\"Region\", \n",
        "    when(col(\"Region\").isNull(), \"Other\").otherwise(col(\"Region\")))\n",
        "\n",
        "print(\"Region distribution:\")\n",
        "df_enriched.groupBy(\"Region\").count().orderBy(desc(\"count\")).show()\n",
        "\n",
        "print(\"\\nStatus distribution:\")\n",
        "df_enriched.groupBy(\"Status\").count().show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. 特征标准化与编码\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 准备 ML 管道的特征列\n",
        "exclude_cols = ['Country', 'Year', 'Status', 'Region', 'Life expectancy ']\n",
        "feature_cols = [c for c in df_enriched.columns if c not in exclude_cols]\n",
        "\n",
        "print(f\"Selected feature columns ({len(feature_cols)})\")\n",
        "\n",
        "# 处理特征列中剩余的空值\n",
        "for col_name in feature_cols:\n",
        "    df_enriched = df_enriched.withColumn(col_name, \n",
        "        when(col(col_name).isNull(), 0.0).otherwise(col(col_name)))\n",
        "\n",
        "# 创建索引器和编码器\n",
        "status_indexer = StringIndexer(inputCol=\"Status\", outputCol=\"StatusIndex\")\n",
        "status_encoder = OneHotEncoder(inputCol=\"StatusIndex\", outputCol=\"StatusVec\")\n",
        "region_indexer = StringIndexer(inputCol=\"Region\", outputCol=\"RegionIndex\")\n",
        "region_encoder = OneHotEncoder(inputCol=\"RegionIndex\", outputCol=\"RegionVec\")\n",
        "\n",
        "# 组装所有特征\n",
        "all_feature_cols = feature_cols + [\"StatusVec\", \"RegionVec\"]\n",
        "assembler = VectorAssembler(inputCols=all_feature_cols, outputCol=\"features_raw\")\n",
        "\n",
        "# 标准化特征\n",
        "scaler = StandardScaler(inputCol=\"features_raw\", outputCol=\"features\", \n",
        "                       withStd=True, withMean=True)\n",
        "\n",
        "print(\"Feature preprocessing pipeline components defined.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. 划分训练与测试集\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 准备带有目标变量的数据集\n",
        "df_ml = df_enriched.filter(col(\"Life expectancy \").isNotNull())\n",
        "\n",
        "# 按 0.8 / 0.2 随机划分（固定 seed）\n",
        "train_df, test_df = df_ml.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "print(f\"Training set size: {train_df.count()}\")\n",
        "print(f\"Test set size: {test_df.count()}\")\n",
        "\n",
        "# 缓存结果提高后续效率\n",
        "train_df.cache()\n",
        "test_df.cache()\n",
        "\n",
        "print(\"\\nTrain set sample:\")\n",
        "train_df.select(\"Country\", \"Year\", \"Life expectancy \", \"Status\", \"Region\").show(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. 建模与比较\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 创建 ML 管道\n",
        "def create_preprocessing_pipeline():\n",
        "    return Pipeline(stages=[\n",
        "        status_indexer,\n",
        "        region_indexer,\n",
        "        status_encoder,\n",
        "        region_encoder,\n",
        "        assembler,\n",
        "        scaler\n",
        "    ])\n",
        "\n",
        "# 定义要比较的模型\n",
        "models = {\n",
        "    'Linear Regression': LinearRegression(featuresCol='features', labelCol='Life expectancy '),\n",
        "    'Decision Tree': DecisionTreeRegressor(featuresCol='features', labelCol='Life expectancy ', seed=42),\n",
        "    'Random Forest': RandomForestRegressor(featuresCol='features', labelCol='Life expectancy ', seed=42),\n",
        "    'GBT': GBTRegressor(featuresCol='features', labelCol='Life expectancy ', seed=42)\n",
        "}\n",
        "\n",
        "# 设置评估指标\n",
        "evaluator_rmse = RegressionEvaluator(labelCol='Life expectancy ', predictionCol='prediction', metricName='rmse')\n",
        "evaluator_mae = RegressionEvaluator(labelCol='Life expectancy ', predictionCol='prediction', metricName='mae')\n",
        "evaluator_r2 = RegressionEvaluator(labelCol='Life expectancy ', predictionCol='prediction', metricName='r2')\n",
        "\n",
        "# 存储结果\n",
        "results = {}\n",
        "best_models = {}\n",
        "\n",
        "# 训练和评估每个模型\n",
        "for model_name, model in models.items():\n",
        "    print(f\"\\nTraining {model_name}...\")\n",
        "    \n",
        "    full_pipeline = Pipeline(stages=create_preprocessing_pipeline().getStages() + [model])\n",
        "    param_grid = ParamGridBuilder().build()\n",
        "    \n",
        "    cv = CrossValidator(\n",
        "        estimator=full_pipeline,\n",
        "        estimatorParamMaps=param_grid,\n",
        "        evaluator=evaluator_r2,\n",
        "        numFolds=5,\n",
        "        seed=42\n",
        "    )\n",
        "    \n",
        "    cv_model = cv.fit(train_df)\n",
        "    predictions = cv_model.transform(test_df)\n",
        "    \n",
        "    rmse = evaluator_rmse.evaluate(predictions)\n",
        "    mae = evaluator_mae.evaluate(predictions)\n",
        "    r2 = evaluator_r2.evaluate(predictions)\n",
        "    \n",
        "    results[model_name] = {'RMSE': rmse, 'MAE': mae, 'R²': r2}\n",
        "    best_models[model_name] = cv_model\n",
        "    \n",
        "    print(f\"{model_name} - RMSE: {rmse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}\")\n",
        "\n",
        "# 显示结果表\n",
        "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
        "print(\"\\nModel Performance Comparison:\")\n",
        "print(results_df.round(4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 选择最佳模型\n",
        "best_model_name = max(results.keys(), key=lambda x: results[x]['R²'])\n",
        "best_model = best_models[best_model_name]\n",
        "\n",
        "print(f\"\\nBest model: {best_model_name}\")\n",
        "print(f\"Performance: R² = {results[best_model_name]['R²']:.4f}, RMSE = {results[best_model_name]['RMSE']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. 运行模型并生成预测结果\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 在 test 集运行预测\n",
        "final_predictions = best_model.transform(test_df)\n",
        "\n",
        "# 输出预测样例\n",
        "print(\"Prediction samples:\")\n",
        "final_predictions.select(\n",
        "    \"Country\", \"Year\", \n",
        "    col(\"Life expectancy \").alias(\"True_Value\"),\n",
        "    col(\"prediction\").alias(\"Predicted_Value\")\n",
        ").show(10)\n",
        "\n",
        "# 保存预测结果\n",
        "final_predictions.select(\n",
        "    \"Country\", \"Year\", \"Status\", \"Region\",\n",
        "    col(\"Life expectancy \").alias(\"True_Value\"),\n",
        "    col(\"prediction\").alias(\"Predicted_Value\")\n",
        ").coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"predictions_output\")\n",
        "\n",
        "print(\"\\nPredictions saved to 'predictions_output' directory.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. 分析模型输出模式\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 计算残差统计\n",
        "residuals_df = final_predictions.withColumn(\"residual\", \n",
        "    col(\"Life expectancy \") - col(\"prediction\"))\n",
        "\n",
        "residual_stats = residuals_df.select(\n",
        "    mean(\"residual\").alias(\"mean_residual\"),\n",
        "    stddev(\"residual\").alias(\"std_residual\")\n",
        ").collect()[0]\n",
        "\n",
        "print(f\"Residual statistics - Mean: {residual_stats['mean_residual']:.4f}, Std: {residual_stats['std_residual']:.4f}\")\n",
        "\n",
        "# 按 Status 分组\n",
        "print(\"\\nAverage predictions by Status:\")\n",
        "residuals_df.groupBy(\"Status\").agg(\n",
        "    mean(\"prediction\").alias(\"avg_prediction\"),\n",
        "    mean(\"Life expectancy \").alias(\"avg_actual\")\n",
        ").show()\n",
        "\n",
        "# 按 Region 分组\n",
        "print(\"\\nAverage predictions by Region:\")\n",
        "residuals_df.groupBy(\"Region\").agg(\n",
        "    mean(\"prediction\").alias(\"avg_prediction\"),\n",
        "    mean(\"Life expectancy \").alias(\"avg_actual\")\n",
        ").orderBy(desc(\"avg_prediction\")).show()\n",
        "\n",
        "# Top 误差样本\n",
        "print(\"\\nTop 10 largest absolute errors:\")\n",
        "top_errors = residuals_df.select(\n",
        "    \"Country\", \"Year\", \"Status\", \"Region\",\n",
        "    \"Life expectancy \", \"prediction\", col(\"residual\").alias(\"error\")\n",
        ").withColumn(\"abs_error\", abs(col(\"error\"))).orderBy(desc(\"abs_error\")).limit(10)\n",
        "top_errors.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 输出特征重要性\n",
        "if best_model_name in ['Decision Tree', 'Random Forest', 'GBT']:\n",
        "    try:\n",
        "        model_stage = best_model.bestModel.stages[-1]\n",
        "        if hasattr(model_stage, 'featureImportances'):\n",
        "            importances = model_stage.featureImportances\n",
        "            print(f\"\\nFeature importance for {best_model_name}:\")\n",
        "            \n",
        "            feature_names = all_feature_cols\n",
        "            importance_list = [(feature_names[i], importances[i]) for i in range(len(feature_names))]\n",
        "            importance_list.sort(key=lambda x: x[1], reverse=True)\n",
        "            \n",
        "            for i, (feature, importance) in enumerate(importance_list[:15]):\n",
        "                print(f\"  {i+1:2d}. {feature}: {importance:.4f}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Feature importance not available: {e}\")\n",
        "else:\n",
        "    print(\"Feature importance not available for Linear Regression model.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. 可视化结果\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# 设置 matplotlib 字体支持（基于 I3.py）\n",
        "plt.rcParams['font.sans-serif'] = ['Arial', 'DejaVu Sans']\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# 转换预测结果为 Pandas 用于可视化\n",
        "viz_data = residuals_df.select(\n",
        "    \"Life expectancy \", \"prediction\", \"residual\", \"Status\", \"Region\"\n",
        ").toPandas()\n",
        "\n",
        "# 设置绘图\n",
        "plt.style.use('default')\n",
        "fig = plt.figure(figsize=(20, 15))\n",
        "\n",
        "# 1. 绘制 Pred vs True 散点图\n",
        "plt.subplot(2, 3, 1)\n",
        "plt.scatter(viz_data['Life expectancy '], viz_data['prediction'], alpha=0.6, s=20)\n",
        "plt.plot([viz_data['Life expectancy '].min(), viz_data['Life expectancy '].max()], \n",
        "         [viz_data['Life expectancy '].min(), viz_data['Life expectancy '].max()], 'r--', lw=2)\n",
        "plt.xlabel('True Life Expectancy')\n",
        "plt.ylabel('Predicted Life Expectancy')\n",
        "plt.title('Predicted vs True Life Expectancy')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 2. 绘制 Residual 直方图\n",
        "plt.subplot(2, 3, 2)\n",
        "plt.hist(viz_data['residual'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "plt.axvline(viz_data['residual'].mean(), color='red', linestyle='--', linewidth=2, \n",
        "           label=f'Mean: {viz_data[\"residual\"].mean():.3f}')\n",
        "plt.xlabel('Residuals')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Residual Distribution')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Residuals vs Fitted\n",
        "plt.subplot(2, 3, 3)\n",
        "plt.scatter(viz_data['prediction'], viz_data['residual'], alpha=0.6, s=20)\n",
        "plt.axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
        "plt.xlabel('Fitted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Residuals vs Fitted Values')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 4. 模型比较柱状图\n",
        "plt.subplot(2, 3, 4)\n",
        "model_names = list(results.keys())\n",
        "r2_scores = [results[name]['R²'] for name in model_names]\n",
        "rmse_scores = [results[name]['RMSE'] for name in model_names]\n",
        "\n",
        "x = np.arange(len(model_names))\n",
        "width = 0.35\n",
        "\n",
        "plt.bar(x - width/2, r2_scores, width, label='R²', alpha=0.8)\n",
        "plt.bar(x + width/2, np.array(rmse_scores)/max(rmse_scores), width, label='RMSE (normalized)', alpha=0.8)\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Model Performance Comparison')\n",
        "plt.xticks(x, [name.replace(' ', '\\n') for name in model_names], rotation=45)\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 5. 按 Status 的预测\n",
        "plt.subplot(2, 3, 5)\n",
        "status_means = viz_data.groupby('Status').agg({\n",
        "    'Life expectancy ': 'mean',\n",
        "    'prediction': 'mean'\n",
        "}).reset_index()\n",
        "\n",
        "x = np.arange(len(status_means))\n",
        "plt.bar(x - 0.2, status_means['Life expectancy '], 0.4, label='Actual', alpha=0.8)\n",
        "plt.bar(x + 0.2, status_means['prediction'], 0.4, label='Predicted', alpha=0.8)\n",
        "plt.xlabel('Status')\n",
        "plt.ylabel('Life Expectancy')\n",
        "plt.title('Predictions by Status')\n",
        "plt.xticks(x, status_means['Status'])\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 6. 按 Region 的预测（前5个地区）\n",
        "plt.subplot(2, 3, 6)\n",
        "region_means = viz_data.groupby('Region').agg({\n",
        "    'Life expectancy ': 'mean',\n",
        "    'prediction': 'mean'\n",
        "}).reset_index().sort_values('prediction', ascending=False).head(5)\n",
        "\n",
        "x = np.arange(len(region_means))\n",
        "plt.bar(x - 0.2, region_means['Life expectancy '], 0.4, label='Actual', alpha=0.8)\n",
        "plt.bar(x + 0.2, region_means['prediction'], 0.4, label='Predicted', alpha=0.8)\n",
        "plt.xlabel('Region')\n",
        "plt.ylabel('Life Expectancy')\n",
        "plt.title('Predictions by Region (Top 5)')\n",
        "plt.xticks(x, region_means['Region'], rotation=45)\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('spark_ml_results.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Visualization saved as 'spark_ml_results.png'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. 模型再迭代（Iteration 2 within Iteration 4）\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 在主模型上扩大 numTrees / maxDepth 网格重新调参\n",
        "print(f\"\\nPerforming enhanced hyperparameter tuning for {best_model_name}...\")\n",
        "\n",
        "# 根据模型类型定义参数网格\n",
        "if best_model_name == 'Random Forest':\n",
        "    param_grid = ParamGridBuilder() \\\n",
        "        .addGrid(models['Random Forest'].numTrees, [50, 100, 200]) \\\n",
        "        .addGrid(models['Random Forest'].maxDepth, [5, 10, 15]) \\\n",
        "        .build()\n",
        "elif best_model_name == 'Decision Tree':\n",
        "    param_grid = ParamGridBuilder() \\\n",
        "        .addGrid(models['Decision Tree'].maxDepth, [5, 10, 15, 20]) \\\n",
        "        .build()\n",
        "elif best_model_name == 'GBT':\n",
        "    param_grid = ParamGridBuilder() \\\n",
        "        .addGrid(models['GBT'].maxIter, [50, 100, 200]) \\\n",
        "        .addGrid(models['GBT'].maxDepth, [3, 5, 7]) \\\n",
        "        .build()\n",
        "else:\n",
        "    param_grid = ParamGridBuilder() \\\n",
        "        .addGrid(models['Linear Regression'].regParam, [0.0, 0.01, 0.1]) \\\n",
        "        .build()\n",
        "\n",
        "# 创建增强交叉验证器\n",
        "enhanced_cv = CrossValidator(\n",
        "    estimator=Pipeline(stages=create_preprocessing_pipeline().getStages() + [models[best_model_name]]),\n",
        "    estimatorParamMaps=param_grid,\n",
        "    evaluator=evaluator_r2,\n",
        "    numFolds=5,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# 拟合增强模型\n",
        "enhanced_model = enhanced_cv.fit(train_df)\n",
        "enhanced_predictions = enhanced_model.transform(test_df)\n",
        "\n",
        "# 计算增强指标\n",
        "enhanced_rmse = evaluator_rmse.evaluate(enhanced_predictions)\n",
        "enhanced_r2 = evaluator_r2.evaluate(enhanced_predictions)\n",
        "\n",
        "# 比较两轮 RMSE / R² 变化\n",
        "print(f\"\\nEnhanced {best_model_name} Results:\")\n",
        "print(f\"Original R²: {results[best_model_name]['R²']:.4f}\")\n",
        "print(f\"Enhanced R²: {enhanced_r2:.4f}\")\n",
        "print(f\"Original RMSE: {results[best_model_name]['RMSE']:.4f}\")\n",
        "print(f\"Enhanced RMSE: {enhanced_rmse:.4f}\")\n",
        "\n",
        "# 保存两轮预测结果对比\n",
        "comparison_results = {\n",
        "    'Model': [f'{best_model_name} (Original)', f'{best_model_name} (Enhanced)'],\n",
        "    'R²': [results[best_model_name]['R²'], enhanced_r2],\n",
        "    'RMSE': [results[best_model_name]['RMSE'], enhanced_rmse]\n",
        "}\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_results)\n",
        "print(\"\\nModel Enhancement Comparison:\")\n",
        "print(comparison_df.round(4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 保存增强预测结果\n",
        "enhanced_predictions.select(\n",
        "    \"Country\", \"Year\", \"Status\", \"Region\",\n",
        "    col(\"Life expectancy \").alias(\"True_Value\"),\n",
        "    col(\"prediction\").alias(\"Enhanced_Prediction\")\n",
        ").coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"enhanced_predictions\")\n",
        "\n",
        "print(\"Enhanced predictions saved to 'enhanced_predictions' directory.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. 收尾准备报告\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 保存最佳增强模型\n",
        "enhanced_model.write().overwrite().save(\"best_life_expectancy_model\")\n",
        "\n",
        "# 最终总结\n",
        "print(\"=\"*60)\n",
        "print(\"ITERATION 4 - BDAS PYSPARK ML PIPELINE SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\nDataset Information:\")\n",
        "print(f\"  - Total records: {df_ml.count():,}\")\n",
        "print(f\"  - Training samples: {train_df.count():,}\")\n",
        "print(f\"  - Test samples: {test_df.count():,}\")\n",
        "print(f\"  - Features after engineering: {len(all_feature_cols)}\")\n",
        "\n",
        "print(f\"\\nModel Performance (Best: {best_model_name}):\")\n",
        "for model_name, metrics in results.items():\n",
        "    marker = \" << BEST\" if model_name == best_model_name else \"\"\n",
        "    print(f\"  - {model_name}: R² = {metrics['R²']:.4f}, RMSE = {metrics['RMSE']:.4f}{marker}\")\n",
        "\n",
        "print(f\"\\nEnhanced Model Results:\")\n",
        "print(f\"  - Enhanced R²: {enhanced_r2:.4f}\")\n",
        "print(f\"  - Enhanced RMSE: {enhanced_rmse:.4f}\")\n",
        "print(f\"  - Improvement in R²: {(enhanced_r2 - results[best_model_name]['R²']):.4f}\")\n",
        "\n",
        "print(f\"\\nOutput Files Generated:\")\n",
        "print(f\"  - predictions_output/ : Original model predictions\")\n",
        "print(f\"  - enhanced_predictions/ : Enhanced model predictions\")\n",
        "print(f\"  - best_life_expectancy_model/ : Saved ML model\")\n",
        "print(f\"  - spark_ml_results.png : Visualization charts\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PIPELINE COMPLETED SUCCESSFULLY!\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 清理和结束环境\n",
        "train_df.unpersist()\n",
        "test_df.unpersist()\n",
        "\n",
        "# spark.stop()\n",
        "\n",
        "print(\"Notebook execution completed. Spark session is ready for further use.\")\n",
        "print(\"To stop the Spark session, uncomment the spark.stop() line above.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
